{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunar Lander Problem\n",
    "The problem consists of an 8-dimensional continuous state space and a discrete action space. The four discrete\n",
    "actions available are: do nothing, fire the left orientation engine, fire the main engine, fire the right orientation\n",
    "engine. The landing pad is always at coordinates (0,0). Coordinates consist of the first two numbers in the state\n",
    "vector. The total reward for moving from the top of the screen to the landing pad ranges from 100 - 140 points\n",
    "varying on the lander placement on the pad. If the lander moves away from the landing pad it is penalized the\n",
    "amount of reward that would be gained by moving towards the pad. An episode finishes if the lander crashes or\n",
    "comes to rest, receiving an additional -100 or +100 points respectively. Each leg ground contact is worth +10\n",
    "points. Firing the main engine incurs a -0.3 point penalty for each occurrence. Landing outside of the landing\n",
    "pad is possible. Fuel is infinite, so, an agent could learn to fly and land on its first attempt. The problem is\n",
    "considered solved when achieving a score of 200 points or higher on average over 100 consecutive runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## States\n",
    "At each time step, a tuple of size 8 is given representing the 8 states: &emsp;  *(x,y,$v_{x}$,$v_{y}$,$\\theta$,$v_{\\theta}$,$leg_{L}$,$leg_{R}$)*\n",
    "State in respective order:\n",
    "- *x-coordinate* \n",
    "- *y-coordinate*\n",
    "- *horizontal velocity ($v_{x}$)*\n",
    "- *vertical velocity ($v_{y}$)*\n",
    "- *angle of lander with respect to verical access*\n",
    "- *angular velocity of the lander*\n",
    "- *boolean for if left leg is touching ground*\n",
    "- *boolean for if right leg is touching ground*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rewards\n",
    "Reward for moving from the top of the screen to the landing pad and coming to rest is about 100-140 points. If the lander moves away from the landing pad, it loses reward. If the lander crashes, it receives an additional -100 points. If it comes to rest, it receives an additional +100 points. Each leg with ground contact is +10 points. Firing the main engine is -0.3 points each frame. Firing the side engine is -0.03 points each frame. Solved is 200 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00676279,  1.4031343 , -0.68501765, -0.34606552,  0.00784321,\n",
       "        0.15516661,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "# define seed for reproducibility\n",
    "seed=222980\n",
    "\n",
    "# initialize environment\n",
    "env = gym.make('LunarLander-v2',render_mode=\"human\")\n",
    "env.action_space.seed(seed)\n",
    "\n",
    "# get info on environment and seed\n",
    "observation, _ = env.reset(seed=seed, options={})\n",
    "\n",
    "# get environment info\n",
    "num_actions = env.action_space.n \n",
    "num_inputs = env.observation_space.shape[0]\n",
    "\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstrate Untrained Simulation\n",
    "- Take random action.\n",
    "- Unpack information after taking simulation step.\n",
    "- Show simulation.\n",
    "- Close environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "for _ in range(100):\n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
